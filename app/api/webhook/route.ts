import { NextRequest, NextResponse } from 'next/server';
import {
  Client,
  WebhookEvent,
  TextMessage,
} from '@line/bot-sdk';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { Stream } from 'stream'; // Node.jsì˜ Stream íƒ€ì…ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

// .env.local íŒŒì¼ì—ì„œ ì„¤ì •í•œ ê°’ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
const lineConfig = {
  channelAccessToken: process.env.LINE_CHANNEL_ACCESS_TOKEN || '',
  channelSecret: process.env.LINE_CHANNEL_SECRET || '',
};

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '');
const lineClient = new Client(lineConfig);

// <<-- ì´ í•¨ìˆ˜ë¥¼ ìƒˆë¡œìš´ ë²„ì „ìœ¼ë¡œ êµì²´! -->>
// Node.js Streamì„ Bufferë¡œ ë³€í™˜í•˜ëŠ” ìˆ˜ì •ëœ í—¬í¼ í•¨ìˆ˜
async function streamToBuffer(stream: Stream): Promise<Buffer> {
  return new Promise((resolve, reject) => {
    const chunks: Buffer[] = [];
    stream.on('data', (chunk) => {
      chunks.push(chunk);
    });
    stream.on('end', () => {
      resolve(Buffer.concat(chunks));
    });
    stream.on('error', reject);
  });
}

// LINEì˜ GET ë¦¬í€˜ìŠ¤íŠ¸ í™•ì¸ìš©
export async function GET() {
  return NextResponse.json({
    status: 'success',
    message: "Webhook is active. Ready to receive POST requests from LINE." 
  });
}

// LINEì˜ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” í•µì‹¬ í•¨ìˆ˜
export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const events: WebhookEvent[] = body.events;

    for (const event of events) {
      if (event.type === 'message' && event.message.type === 'image') {
        // 1. LINE ì„œë²„ë¡œë¶€í„° ì´ë¯¸ì§€ ì½˜í…ì¸ (Stream) ê°€ì ¸ì˜¤ê¸°
        const response = await lineClient.getMessageContent(event.message.id);
        
        // 2. Streamì„ Bufferë¡œ, Bufferë¥¼ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜
        const buffer = await streamToBuffer(response as unknown as Stream);
        const imageBase64 = buffer.toString('base64');

        // 3. Gemini Vision API í˜¸ì¶œ
        const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });
        const prompt = "ì´ ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ëœë“œë§ˆí¬ì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”? ì´ ì¥ì†Œì— ëŒ€í•´ ëª¨ë¥´ëŠ” ì‚¬ëŒì—ê²Œ ì„¤ëª…í•˜ë“¯ì´, ì—­ì‚¬ë‚˜ íŠ¹ì§•ì„ í¬í•¨í•´ì„œ 3ë¬¸ì¥ìœ¼ë¡œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.";
        
        const result = await model.generateContent([
          prompt,
          { inlineData: { data: imageBase64, mimeType: 'image/jpeg' } },
        ]);
        
        const aiResponseText = result.response.text();
        console.log('ğŸ¤– AIì˜ ë‹µë³€:', aiResponseText);

        // 4. ë¶„ì„ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ë‹µì¥ìœ¼ë¡œ ë³´ë‚´ê¸°
        const replyMessage: TextMessage = {
          type: 'text',
          text: aiResponseText,
        };
        await lineClient.replyMessage(event.replyToken, replyMessage);
      }
    }

    return NextResponse.json({ status: 'ok' });

  } catch (error) {
    console.error('âŒ ì—ëŸ¬ ë°œìƒ:', error);
    return NextResponse.json({ status: 'error' }, { status: 500 });
  }
}